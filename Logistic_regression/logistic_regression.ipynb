{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: This is a visualized version of logistic regression lib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#This is a implementation and library for binary classification, a.k.a logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load iris dataset for debugging\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "#print(iris['data'])    #input value of dataset\n",
    "#print(iris['target'])   #True label of iris datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "In order to implement logistic regression, we need to initialize parameters w and b, note that when using logistic regression, \n",
    "we have only one computing unit in the neural network. Therefore parameters can be initialized to all zeros. \n",
    "However, if we are using multiple computing units(e.g. sigmoid or relu), it is required to initialize the parameter w randomly, while\n",
    "b can be set to all zeros.\n",
    "'''\n",
    "def logistic_parameter_initialize(x_dim):\n",
    "    # x_dim indicates the dimensions of input feature,a bias unit b is defaultly set.\n",
    "    w = np.zeros((1,x_dim))\n",
    "    b = 0\n",
    "    \n",
    "    parameter = {'w':w,'b':b}\n",
    "    return parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = logistic_parameter_initialize(4)\n",
    "params['w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementation of sigmoid function\n",
    "def sigmoid(z):\n",
    "    value = 1/(1+np.exp(-z))\n",
    "    return value\n",
    "\n",
    "#plot Sigmoid function \n",
    "plt.figure(figsize=(4,3))\n",
    "plt.title('Sigmoid function\\'s shape')\n",
    "z = np.linspace(-10,10)\n",
    "plt.plot(z,sigmoid(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note the dimensions of vectors:\n",
    "# w - (1,x_dims)\n",
    "# b - (1,x_dims) *broadcasted*\n",
    "# X - (x_dims,m) *m=number of samples\n",
    "\n",
    "\n",
    "# Forward propagation step: compute the predicted y's label\n",
    "def forward_prop(w,b,X):\n",
    "    z = np.dot(w,X)+b\n",
    "    a = sigmoid(z)\n",
    "    return z,a\n",
    "\n",
    "# Compute cost function: used to check convergence\n",
    "def compute_cost(a,y):\n",
    "    m = a.shape[1]\n",
    "    cost = -np.sum(y*np.log(a)+(1-y)*np.log(1-a))/m\n",
    "    return cost\n",
    "\n",
    "# Back propagation step: compute partial derivatives of each parameter respectively\n",
    "def back_prop(X,a,y):\n",
    "    m = a.shape[1]\n",
    "    dz = a - y\n",
    "    dw = np.dot(X,dz.T).T/m\n",
    "    db= np.sum(dz)/m\n",
    "    # Note: dw should have the same dimension as w have.Therefore back_prop return dw.T\n",
    "    return dw,db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The overall implementation of trainning a logistic regression\n",
    "def train_logistic_regression(X,y,number_of_iteration = 1000,learning_rate = 0.03,print_cost = True,plot_cost = True):\n",
    "    # Dimension convert: make sure all vectors are in proper shapes.\n",
    "    y = y.reshape(1,-1)   # y is a row vector\n",
    "    m = y.shape[1]  #  m = total number of trainning examples\n",
    "    X = X.reshape(-1,m)\n",
    "    x_dim = X.shape[0]\n",
    "    \n",
    "    params = logistic_parameter_initialize(x_dim)\n",
    "    w = params['w']\n",
    "    b = params['b']\n",
    "    \n",
    "    if(plot_cost == True):\n",
    "        i_curve = []\n",
    "        cost_curve = []\n",
    "        plt.figure(figsize=(5,5))\n",
    "        plt.title('Cross entrophy of regression')\n",
    "    \n",
    "    for i in range(1,number_of_iteration+1):\n",
    "        z,a = forward_prop(w,b,X)\n",
    "        dw,db = back_prop(X,a,y)\n",
    "        w = w - learning_rate*dw\n",
    "        b = b - learning_rate*db\n",
    "        cost = compute_cost(a,y)\n",
    "        # Visualize the process of regression\n",
    "        if(i%100 == 0 and print_cost == True):\n",
    "            print('number of iterations:{}, cost = {}'.format(i,cost))\n",
    "        if(i%100 == 0 and plot_cost == True):\n",
    "            i_curve.append(i)\n",
    "            cost_curve.append(cost)\n",
    "    if(plot_cost==True):        \n",
    "        i_curve = np.reshape(i_curve,(1,-1))\n",
    "        cost_curve = np.reshape(cost_curve,(1,-1))\n",
    "        plt.scatter(i_curve,cost_curve)\n",
    "    \n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Goal:Wanna classify Iris's class {}, that's label{}(original)\".format(iris.target_names[0],0))\n",
    "#Preprocess ground true labels, since the original dataset has 3 kinds of iris,therefore y = 0,1,2\n",
    "print('But the original iris dataset was as below:')\n",
    "y = iris['target']\n",
    "print(y)\n",
    "for index in range(len(y)):\n",
    "    if y[index] == 0: # class 0 \n",
    "        y[index] = 1\n",
    "    else:\n",
    "        y[index] = 0\n",
    "print('So label set is redefined as below:')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_logistic_regression(iris['data'],y,number_of_iteration = 10000,learning_rate = 0.03,print_cost = False,plot_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
